{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Spam Filter From Scratch\n",
    "\n",
    "Although referred to as \"Idiot Bayes\" by some, Naive Bayes models perform surprisingly well despite strong independence assumptions in the model. In this project we will build a spam classifier from scratch for SMS messages using Multinomial Naive Bayes which is known to suit situations where data can be turned into counts, such as word counts in text.\n",
    "\n",
    "You can find more information about the dataset by clicking [here](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection).\n",
    "\n",
    "## 1. Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"Label\", \"SMS\"])\n",
    "collection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection[\"Label\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, non-spam messages are labelled as \"ham\" and there's a lot more non-spam mails compared to spam mails.\n",
    "\n",
    "## 2. Preprocessing\n",
    "\n",
    "As a first step, we will randomize the entire dataset, then split it into the training and test sets. Training set will consist of 80% of the dataset, leaving 20% for testing purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865441\n",
       "spam    0.134559\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify random state to make sure the results are reproducable:\n",
    "sampled_set = collection.sample(frac=1, random_state=1)\n",
    "\n",
    "#Split into 80% - 20% sets:\n",
    "train_set = sampled_set[:4459].copy().reset_index(drop=True)\n",
    "test_set = sampled_set[4459:].copy().reset_index(drop=True)\n",
    "\n",
    "train_set[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.867925\n",
       "spam    0.132075\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"Label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we first read the dataset, we have checked value counts for the labels. We have found that 87% of the messages were labelled \"ham\" whereas 13% were labelled spam. We can see that our test and training sets have similar proportions for each value.\n",
    "\n",
    "We will now work on the SMS column, starting with removing punctuation and making all letters lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[\"SMS\"] = train_set[\"SMS\"].str.replace(r\"\\W\", \" \").str.lower()\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a vocabulary for the training set. We will use sets for this to prevent duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ibm', 'monkey', 'sam', 'perform', 'still']\n"
     ]
    }
   ],
   "source": [
    "train_set[\"SMS\"] = train_set[\"SMS\"].str.split()\n",
    "\n",
    "vocab = []\n",
    "for message in train_set[\"SMS\"]:\n",
    "    for word in message:\n",
    "        vocab.append(word)\n",
    "        \n",
    "vocab = set(vocab) #removing duplicates\n",
    "vocab = list(vocab)\n",
    "print(vocab[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now create a dictionary containing the words as keys and word counts per SMS. Then, we will form a DataFrame from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>ibm</th>\n",
       "      <th>monkey</th>\n",
       "      <th>sam</th>\n",
       "      <th>perform</th>\n",
       "      <th>still</th>\n",
       "      <th>secretary</th>\n",
       "      <th>in2</th>\n",
       "      <th>figure</th>\n",
       "      <th>...</th>\n",
       "      <th>rgent</th>\n",
       "      <th>help</th>\n",
       "      <th>alive</th>\n",
       "      <th>fne</th>\n",
       "      <th>ibh</th>\n",
       "      <th>pub</th>\n",
       "      <th>jog</th>\n",
       "      <th>duo</th>\n",
       "      <th>08000930705</th>\n",
       "      <th>unconscious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  ibm  monkey  sam  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]    0       0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...    0       0    0   \n",
       "2   ham                    [welp, apparently, he, retired]    0       0    0   \n",
       "3   ham                                           [havent]    0       0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0       0    0   \n",
       "\n",
       "   perform  still  secretary  in2  figure  ...  rgent  help  alive  fne  ibh  \\\n",
       "0        0      0          0    0       0  ...      0     0      0    0    0   \n",
       "1        0      0          0    0       0  ...      0     0      0    0    0   \n",
       "2        0      0          0    0       0  ...      0     0      0    0    0   \n",
       "3        0      0          0    0       0  ...      0     0      0    0    0   \n",
       "4        0      0          0    0       0  ...      0     0      0    0    0   \n",
       "\n",
       "   pub  jog  duo  08000930705  unconscious  \n",
       "0    0    0    0            0            0  \n",
       "1    0    0    0            0            0  \n",
       "2    0    0    0            0            0  \n",
       "3    0    0    0            0            0  \n",
       "4    0    0    0            0            0  \n",
       "\n",
       "[5 rows x 7787 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms = {word: [0] * len(train_set[\"SMS\"]) for word in vocab}\n",
    "\n",
    "for index, message in enumerate(train_set[\"SMS\"]):\n",
    "    for word in message:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "        \n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "training_set = pd.concat([train_set, word_counts], axis=1)\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating our spam filter\n",
    "\n",
    "We will be using the probabilities of the equations below for classification:\n",
    "\n",
    "\\begin{equation}\n",
    "P(spam | w_1,w_2, ..., w_n) \\propto P(spam) \\cdot \\prod_{i=1}^{n}P(w_i|spam) \\\\\n",
    "P(ham | w_1,w_2, ..., w_n) \\propto P(ham) \\cdot \\prod_{i=1}^{n}P(w_i|ham)\n",
    "\\end{equation}\n",
    "\n",
    "For each P(w|Spam) and P(w|Ham) in the formulas above, we will be using these equations with Laplace smoothing:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|spam) = \\frac{N_{w_i|spam} + \\alpha}{N_{spam} + \\alpha \\cdot N_{vocabulary}} \\\\\n",
    "P(w_i|ham) = \\frac{N_{w_i|ham} + \\alpha}{N_{ham} + \\alpha \\cdot N_{vocabulary}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13455931823278763 0.8654406817672123\n"
     ]
    }
   ],
   "source": [
    "n_spam = sum([len(row[1]) for row in training_set if row[0] == \"spam\"])\n",
    "n_ham = sum([len(row[1]) for row in training_set if row[0] == \"ham\"])\n",
    "n_vocab = len(vocab)\n",
    "\n",
    "p_spam = training_set[\"Label\"].value_counts()[\"spam\"] / training_set[\"Label\"].shape[0]\n",
    "p_ham = training_set[\"Label\"].value_counts()[\"ham\"] / training_set[\"Label\"].shape[0]\n",
    "\n",
    "print(p_spam, p_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the constants, we will move on to calculating the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_df = training_set[training_set[\"Label\"] == \"spam\"].copy()\n",
    "ham_df = training_set[training_set[\"Label\"] == \"ham\"].copy()\n",
    "\n",
    "alpha = 1 #Since we use Laplace smoothing\n",
    "\n",
    "spam_params = {word: (sum(count) + alpha) / (n_spam + (alpha * n_vocab)) for word, count in spam_df.iloc[:, 2:].iteritems()}\n",
    "ham_params = {word: (sum(count) + alpha) / (n_ham + (alpha * n_vocab)) for word, count in ham_df.iloc[:, 2:].iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now calculated our parameters, too. We can now begin writing our function.\n",
    "\n",
    "## 4. Classification process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.728443394127009e-05\n",
      "P(Ham|message): 0.00022233543526453754\n",
      "Label: Non-spam\n"
     ]
    }
   ],
   "source": [
    "def classify(message, verbose=True):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message).lower().split()\n",
    "    \n",
    "    try:\n",
    "        p_spam_given_message = p_spam * np.prod([spam_params[word] for word in message])\n",
    "        p_ham_given_message = p_ham * np.prod([ham_params[word] for word in message])\n",
    "    except:\n",
    "        p_spam_given_message = p_spam\n",
    "        p_ham_given_message = p_ham\n",
    "    \n",
    "    if verbose == True:\n",
    "        print(\"P(Spam|message):\", p_spam_given_message)\n",
    "        print(\"P(Ham|message):\", p_ham_given_message)\n",
    "        \n",
    "        if p_ham_given_message > p_spam_given_message:\n",
    "            print(\"Label: Non-spam\")\n",
    "        elif p_ham_given_message < p_spam_given_message:\n",
    "            print(\"Label: Spam\")\n",
    "        else:\n",
    "            print(\"This message carries equal probabilities of being non-spam vs. spam. Please consult a human for accurate classification.\")\n",
    "    else:\n",
    "        if p_ham_given_message > p_spam_given_message:\n",
    "            return \"ham\"\n",
    "        elif p_ham_given_message < p_spam_given_message:\n",
    "            return \"spam\"\n",
    "        else:\n",
    "            return \"needs human classification\"\n",
    "\n",
    "classify(\"success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function seems to work well!\n",
    "\n",
    "## 5. Measuring Accuracy\n",
    "\n",
    "In this step, we will be measuring our function's accuracy on the test set using the formula below:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Accuracy} = \\frac{\\text{number of correctly classified messages}}{\\text{total number of classified messages}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     1062\n",
       "spam      51\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correctly_classified = 0\n",
    "total_classified = test_set.shape[0]\n",
    "\n",
    "test_set[\"prediction\"] = test_set[\"SMS\"].apply(classify, verbose=False)\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row[\"Label\"] == row[\"prediction\"]:\n",
    "        correctly_classified += 1\n",
    "        \n",
    "test_set[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions made by our function are 91.37% accurate.\n",
      "Correct: 1017\n",
      "Incorrect: 96\n",
      "Total: 1113\n"
     ]
    }
   ],
   "source": [
    "accuracy = correctly_classified / total_classified\n",
    "print(\"Predictions made by our function are {pred}% accurate.\\nCorrect: {correct}\\nIncorrect: {inc}\\nTotal: {tot}\".format(pred=round(accuracy * 100, 2), correct=correctly_classified, inc=total_classified - correctly_classified, tot=total_classified))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "\n",
    "In this project, we have built a spam classifier from scratch. As we can see in the final step's output, our spam filter has an accuracy of ~91.37% with 1017 correctly classified messages out of 1113."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
